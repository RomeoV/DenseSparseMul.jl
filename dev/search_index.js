var documenterSearchIndex = {"docs":
[{"location":"#ThreadedDenseSparseMul.jl","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"ThreadedDenseSparseMul.jl is a Julia package that provides a threaded implementation of dense-sparse matrix multiplication, built on top of Polyester.jl.","category":"page"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"This package addresses the need for fast computation of C ← C + D × S, where D and S are dense and sparse matrices, respectively. It differs from existing solutions in the following ways:","category":"page"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"SparseArrays.jl doesn't support threaded multiplication.\nMKLSparse.jl doesn't support dense × sparsecsc multiplication directly.\nThreadedSparseCSR.jl and ThreadedSparseArrays.jl support only sparse × dense multiplication.","category":"page"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"ThreadedDenseSparseMul.jl shows significant performance improvements over base Julia implementations, especially for large matrices.","category":"page"},{"location":"#Performance","page":"ThreadedDenseSparseMul.jl","title":"Performance","text":"","category":"section"},{"location":"#[fastdensesparsemul_threaded!](@ref)-outperforms-MKLSparse-by-2x:","page":"ThreadedDenseSparseMul.jl","title":"fastdensesparsemul_threaded! outperforms MKLSparse by 2x:","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"(Image: `fastdensesparsemul!` outperforms MKLSparse by 2x.)","category":"page"},{"location":"#[fastdensesparsemul_outer_threaded!](@ref)-outperforms-SparseArrays-by-4x:","page":"ThreadedDenseSparseMul.jl","title":"fastdensesparsemul_outer_threaded! outperforms SparseArrays by 4x:","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"(Image: `fastdensesparsemulmul!` outperforms SparseArrays for outer product by 4x.)","category":"page"},{"location":"#Usage","page":"ThreadedDenseSparseMul.jl","title":"Usage","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"To use ThreadedDenseSparseMul.jl, simply install and import the package, and launch Julia with some threads (e.g., julia --threads=auto). Then, you can use any of the following accelerated functions:","category":"page"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"using ThreadedDenseSparseMul\nusing SparseArrays\n\nA = rand(1_000, 2_000)\nB = sprand(2_000, 30_000, 0.05)\nbuf = similar(A, size(A,1), size(B,2))  # prealloc\n\nfastdensesparsemul!(buf, A, B, 1, 0)\nfastdensesparsemul_threaded!(buf, A, B, 1, 0)\nfastdensesparsemul_outer!(buf, @view(A[:, 1]), B[1,:], 1, 0)\nfastdensesparsemul_outer_threaded!(buf, @view(A[:, 1]), B[1,:], 1, 0)","category":"page"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"The interface is adapted from the 5-parameter definition used by mul! and BLAS.","category":"page"},{"location":"#API-Reference","page":"ThreadedDenseSparseMul.jl","title":"API Reference","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"Modules = [ThreadedDenseSparseMul]","category":"page"},{"location":"#ThreadedDenseSparseMul.fastdensesparsemul!-Union{Tuple{T}, Tuple{Union{Matrix{T}, SubArray{T, 2, Matrix{T}}}, Union{Matrix{T}, SubArray{T, 2, Matrix{T}}}, SparseArrays.SparseMatrixCSC{T}, Number, Number}} where T","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.fastdensesparsemul!","text":"fastdensesparsemul!(C, A, B, α, β)\n\nBLAS like interface, computing C .= β*C + α*A*B, but way faster than Base would.\n\nAlso see fastdensesparsemul_threaded! for a multi-threaded version using Polyester.jl.\n\n\n\n\n\n","category":"method"},{"location":"#ThreadedDenseSparseMul.fastdensesparsemul_outer!-Union{Tuple{T}, Tuple{Union{Matrix{T}, SubArray{T, 2, Matrix{T}}}, Union{Vector{T}, SubArray{T, 1, Matrix{T}}}, SparseArrays.SparseVector{T}, Number, Number}} where T","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.fastdensesparsemul_outer!","text":"fastdensesparsemul_outer!(C, a, b, α, β)\n\nFast outer product when computing C .= β*C + α * a*b', but way faster than Base would.\n\na is a dense vector (or view), b is a sparse vector, C is a dense matrix (or view).\n\nAlso see fastdensesparsemul_outer_threaded! for a multi-threaded version using Polyester.jl.\n\n\n\n\n\n","category":"method"},{"location":"#ThreadedDenseSparseMul.fastdensesparsemul_outer_threaded!-Union{Tuple{T}, Tuple{Union{Matrix{T}, SubArray{T, 2, Matrix{T}}}, Union{Vector{T}, SubArray{T, 1, Matrix{T}}}, SparseArrays.SparseVector{T}, Number, Number}} where T","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.fastdensesparsemul_outer_threaded!","text":"fastdensesparsemul_outer_threaded!(C, a, b, α, β)\n\nThreaded, fast outer product when computing C .= β*C + α * a*b', but way faster than Base would, using Polyester.jl.\n\na is a dense vector (or view), b is a sparse vector, C is a dense matrix (or view).\n\nAlso see fastdensesparsemul_outer! for a single-threaded version.\n\n\n\n\n\n","category":"method"},{"location":"#ThreadedDenseSparseMul.fastdensesparsemul_threaded!-Union{Tuple{T}, Tuple{Union{Matrix{T}, SubArray{T, 2, Matrix{T}}}, Union{Matrix{T}, SubArray{T, 2, Matrix{T}}}, SparseArrays.SparseMatrixCSC{T}, Number, Number}} where T","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.fastdensesparsemul_threaded!","text":"fastdensesparsemul!(C, A, B, α, β)\n\nThreaded, BLAS like interface, computing C .= β*C + α*A*B, but way faster than Base would. Also see fastdensesparsemul! for a single-threaded version.\n\n\n\n\n\n","category":"method"},{"location":"#ThreadedDenseSparseMul.get_num_threads-Tuple{}","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.get_num_threads","text":"ThreadedSparseCSR.get_num_threads()\n\nGets the number of threads used in sparse csr matrix - vector multiplication.\n\n\n\n\n\n","category":"method"},{"location":"#ThreadedDenseSparseMul.set_num_threads-Tuple{Int64}","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.set_num_threads","text":"ThreadedSparseCSR.set_num_threads(n::Int)\n\nSets the number of threads used in sparse csr matrix - vector multiplication.\n\n\n\n\n\n","category":"method"},{"location":"#Implementation","page":"ThreadedDenseSparseMul.jl","title":"Implementation","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"The core implementation is quite simple, leveraging Polyester.jl for threading. The result is simply something similar to","category":"page"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"function fastdensesparsemul_threaded!(C::AbstractMatrix, A::AbstractMatrix, B::SparseMatrixCSC, α::Number, β::Number)\n    @batch for j in axes(B, 2)\n        C[:, j] .*= β\n        C[:, j] .+= A * (α.*B[:, j])\n    end\n    return C\nend","category":"page"},{"location":"#Contributing","page":"ThreadedDenseSparseMul.jl","title":"Contributing","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"Contributions to ThreadedDenseSparseMul.jl are welcome! Please feel free to submit issues or pull requests on the GitHub repository.","category":"page"},{"location":"#License","page":"ThreadedDenseSparseMul.jl","title":"License","text":"","category":"section"},{"location":"","page":"ThreadedDenseSparseMul.jl","title":"ThreadedDenseSparseMul.jl","text":"ThreadedDenseSparseMul.jl is licensed under the MIT License. See the LICENSE file in the package repository for more details.","category":"page"}]
}
